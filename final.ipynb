{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHQzS-LFzED1"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwlQE6fozED4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt # komoran, han, kkma\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv7cFWMfzED5"
      },
      "source": [
        "## 불용어 사전 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3cc_h_8zED7"
      },
      "outputs": [],
      "source": [
        "df_all_quarter = pd.read_csv('/content/all_quarter.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oO4M0lwzED8"
      },
      "outputs": [],
      "source": [
        "def data_preprocess(curat_path, word_path):\n",
        "    df = pd.read_csv(curat_path, index_col = 0) # read curating csv file\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    df = df.drop('Unnamed: 0.1', axis=1) # 불필요한 열 삭제\n",
        "    df = df.rename(columns={'total_reivew' : 'total_review'}) # 사용할 열 이름 재정의\n",
        "\n",
        "    words = df_all_quarter['0'].tolist() # df_all_quarter df의 '0' 컬럼 list화\n",
        "    words = [x for x in words if pd.isna(x) != True] # nan값 제거\n",
        "\n",
        "    df_word_count = pd.read_csv(word_path, index_col = 0) # word df read\n",
        "    words_list = df_word_count['단어'].tolist()\n",
        "\n",
        "    return words, words_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub8-sHQmzED9"
      },
      "outputs": [],
      "source": [
        "one_words, fir_words_list = data_preprocess('/content/2021_1분기.csv', '/content/1분기단어.csv')\n",
        "two_words, sec_words_list = data_preprocess('/content/2021_2분기.csv', '/content/2분기단어.csv')\n",
        "thr_words, thr_words_list = data_preprocess('/content/2021_3분기.csv', '/content/3분기단어.csv')\n",
        "fou_words, fou_words_list = data_preprocess('/content/2021_4분기.csv', '/content/4분기단어.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiKyydIkzED9"
      },
      "source": [
        "## 각 분기마다 단어를 비교하여 불용어 사전 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paYTGOxszED-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "first_words = [x for x in fir_words_list if x not in sec_words_list]\n",
        "first_words = [x for x in first_words if x not in thr_words_list]\n",
        "first_words = [x for x in first_words if x not in fou_words_list]\n",
        "len(first_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvhHXCh-zED-"
      },
      "outputs": [],
      "source": [
        "second_words = [x for x in sec_words_list if x not in fir_words_list]\n",
        "second_words = [x for x in second_words if x not in thr_words_list]\n",
        "second_words = [x for x in second_words if x not in fou_words_list]\n",
        "len(second_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzYTTj2ZzED_"
      },
      "outputs": [],
      "source": [
        "third_words = [x for x in thr_words_list if x not in fir_words_list]\n",
        "third_words = [x for x in third_words if x not in sec_words_list]\n",
        "third_words = [x for x in third_words if x not in fou_words_list]\n",
        "len(third_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YrKaeYbzED_"
      },
      "outputs": [],
      "source": [
        "fourth_words = [x for x in fou_words_list if x not in fir_words_list]\n",
        "fourth_words = [x for x in fourth_words if x not in sec_words_list]\n",
        "fourth_words = [x for x in fourth_words if x not in thr_words_list]\n",
        "len(fourth_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYEVmpL6zEEA"
      },
      "source": [
        "## 최종 불용어 사전 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyMACZE2zEEA"
      },
      "outputs": [],
      "source": [
        "df_word_count = pd.read_csv('/content/1분기단어.csv', index_col = 0)\n",
        "df_word_count2 = pd.read_csv('/content/2분기단어.csv', index_col = 0)\n",
        "df_word_count3 = pd.read_csv('/content/3분기단어.csv', index_col = 0)\n",
        "df_word_count4 = pd.read_csv('/content/4분기단어.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUrOMsqnzEEA"
      },
      "outputs": [],
      "source": [
        "one_stopwords = [x for x in df_word_count['단어'] if x not in first_words]\n",
        "two_stopwords = [x for x in df_word_count2['단어'] if x not in second_words]\n",
        "thr_stopwords = [x for x in df_word_count3['단어'] if x not in third_words]\n",
        "fou_stopwords = [x for x in df_word_count4['단어'] if x not in fourth_words]\n",
        "print(len(one_stopwords), len(two_stopwords), len(thr_stopwords), len(fou_stopwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDx6xsOqzEEB"
      },
      "outputs": [],
      "source": [
        "stopwords = [one_stopwords, two_stopwords, thr_stopwords, fou_stopwords]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYfW-XWbzEEB"
      },
      "outputs": [],
      "source": [
        "df_product = pd.read_csv('/content/불용어 제거한 상세설명_.csv', index_col = 0)\n",
        "\n",
        "# 결측치 제거\n",
        "df_product = df_product.dropna()\n",
        "df_product = df_product.reset_index(drop=True)\n",
        "\n",
        "# 중복 제거\n",
        "df_product = df_product.drop_duplicates(['상품설명'], ignore_index = True)\n",
        "df_product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8zTgekNzEEB"
      },
      "outputs": [],
      "source": [
        "product_stopwords = ['원단', '사용', '착용', '실루엣', '디자인', '가공', '구성', '적용', '활용', '제품', '제공', '용도', '사이즈', '아이템', '완성', '공정', '포면', '구조', '위해', '가지', '포함', '연출', '형태',\n",
        "                 '일리', '컬러', '제작', '보장', '소재', '이용', '일반', '단계', '덕분', '부위', '사양', '방식', '통해', '추가']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqy4XqFQzEEB"
      },
      "source": [
        "## 큐레이팅과 상품 설명 합치기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VuADBdczEEB"
      },
      "outputs": [],
      "source": [
        "def concat_data(df):\n",
        "    curating = ''.join(df['total_review'].tolist())\n",
        "    df_curating = pd.DataFrame([['큐레이팅', curating]], columns=['상품번호', '상품설명'])\n",
        "    df_curating = pd.concat([df_curating, df_product])\n",
        "    df_curating = df_curating.reset_index(drop=True)\n",
        "\n",
        "    return df_curating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ544jAPzEEC"
      },
      "outputs": [],
      "source": [
        "df_1 = pd.read_csv('/content/2021_1분기.csv', index_col = 0)\n",
        "df_2 = pd.read_csv('/content/2021_2분기.csv', index_col = 0)\n",
        "df_3 = pd.read_csv('/content/2021_3분기.csv', index_col = 0)\n",
        "df_4 = pd.read_csv('/content/2021_4분기.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giABd0GjzEEC"
      },
      "outputs": [],
      "source": [
        "df_curating_11 = concat_data(df_1)\n",
        "df_curating_22 = concat_data(df_2)\n",
        "df_curating_33 = concat_data(df_3)\n",
        "df_curating_44 = concat_data(df_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5pzqE3BzEEC"
      },
      "source": [
        "## TF_IDF를 이용하여 분기별 상품 추출 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUynotVZzEEC"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXdvlzYhzEED"
      },
      "outputs": [],
      "source": [
        "def get_title(num):\n",
        "  # 상품번호에 따른 상품명 크롤링 함수\n",
        "  url = 'https://www.musinsa.com/app/goods/'+str(num)\n",
        "  headers = {\n",
        "      'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.57 Whale/3.14.133.23 Safari/537.36'\n",
        "  }\n",
        "  resp = requests.get(url, headers=headers)\n",
        "  soup = BeautifulSoup(resp.text)\n",
        "  title_tags = soup.select('#page_product_detail > div.right_area.page_detail_product > div.right_contents.section_product_summary > span > em')\n",
        "\n",
        "  title = title_tags[0].text\n",
        "\n",
        "  return title\n",
        "\n",
        "def text_cleaning(text, stopwords):\n",
        "    # text를 tokenizer하고 불용어를 제거한 단어를 return해주는 함수\n",
        "    hangul = re.compile('[^ ㄱ-ㅣ 가-힣]')  # 정규 표현식 처리\n",
        "    result = hangul.sub('', text)\n",
        "    okt = Okt()  # 형태소 추출\n",
        "    nouns = okt.nouns(result)\n",
        "    nouns = [x for x in nouns if len(x) > 1]  # 한글자 키워드 제거\n",
        "    \n",
        "    if len(text) > 10000:\n",
        "      nouns = [x for x in nouns if x not in stopwords]\n",
        "    else:\n",
        "      nouns = [x for x in nouns if x not in product_stopwords]\n",
        "    return nouns\n",
        "\n",
        "def vect_count(data1, num):\n",
        "    # tf-idf를 하여, 유사도, 상품번호를 print 및 return 해주는 함수\n",
        "    tfidf = TfidfVectorizer(tokenizer = lambda x: text_cleaning(x, stopwords[num]), max_features=300, min_df=20, max_df=0.2)\n",
        "    tf_idf_vect = tfidf.fit_transform(data1['상품설명'])\n",
        "    tf_idf_vect\n",
        "    \n",
        "    similarity_simple_pair = cosine_similarity(tf_idf_vect[0], tf_idf_vect)\n",
        "\n",
        "    sorted_index = similarity_simple_pair.argsort()[:, ::-1] # 인덱스 내림차순으로 저장\n",
        "    sorted_index = sorted_index[:, 1:]\n",
        "    print(sorted_index.reshape(-1)[:10])\n",
        "\n",
        "    curating_sim_value = np.sort(similarity_simple_pair.reshape(-1))[::-1] # [::-1]은 처음부터 끝까지 역순으로 정렬\n",
        "    curating_sim_value = curating_sim_value[1:]\n",
        "\n",
        "    curating_sim_df = pd.DataFrame()\n",
        "    curating_sim_df['상품코드'] = data1.iloc[sorted_index.reshape(-1)[:10].tolist()]['상품번호']\n",
        "    curating_sim_df['유사도'] = curating_sim_value[:10]\n",
        "    print(curating_sim_value[:10])\n",
        "\n",
        "    curating_sim_df['상품코드'] = curating_sim_df['상품코드'].astype(str)\n",
        "    sns.barplot(x = '유사도', y = '상품코드', data = curating_sim_df);\n",
        "    plt.show()\n",
        "\n",
        "    return curating_sim_df['상품코드']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYYcHUygzEED"
      },
      "outputs": [],
      "source": [
        "code1 = vect_count(df_curating_11, 0)\n",
        "code2 = vect_count(df_curating_22, 1)\n",
        "code3 = vect_count(df_curating_33, 2)\n",
        "code4 = vect_count(df_curating_44, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWkhoT_OzEED"
      },
      "outputs": [],
      "source": [
        "code_list = [code1, code2, code3, code4]\n",
        "\n",
        "for idx, code in enumerate(code_list):\n",
        "  print('')\n",
        "  print(idx + 1, '분기')\n",
        "  for num in code.tolist():\n",
        "    print(get_title(num))\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('mmdet': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5020d18e2c1655d0ec59981588cf0abbaf8343e2dd4be620663615197c47b968"
      }
    },
    "colab": {
      "name": "final.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}